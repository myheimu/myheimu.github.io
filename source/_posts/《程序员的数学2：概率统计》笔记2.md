---
title: 《程序员的数学2：概率统计》笔记2
date: 2019-04-28
updated: 2019-05-03
categories:
- 数学
tags:
- 读书笔记
- 概率论
permalink: probability-and-statistics-note-2
mathjax: true
---

* {% post_link probability-and-statistics-note-1 %}
* {% post_link probability-and-statistics-note-2 %}
* {% post_link probability-and-statistics-note-3 %}
----

# 第5章 协方差矩阵、多元正态分布与椭圆
> A：已收到去年入学考试成绩数据，我便马上分析了一下，发现使用的统计软件有问题啊。  
> B：怎么了？  
> A：这个软件预测在模拟考中考出700分的人实际考试时得分为650分。以防万一又反过来拿650分作为实际考试成绩试了一下，结果得出的模拟考分数只有600。按理说应该得到700分才对吧？  
> B：嗯……依然是槽点太多不知道该说什么才好了。你还是重新学习一下多元正态分布的性质吧。

（PS：下文中“椭圆”一般代表对椭圆、椭球、高维椭球等的统称）

## 协方差与相关系数
随机变量 $X,Y$ 的期望值分别是 $\mu,v$，则 $X$ 与 $Y$ 的协方差定义为：
$$\mathrm{Cov}[X,Y] \equiv \mathrm{E}[(X-μ)(Y-v)]$$

协方差>0 称X与Y正相关，协方差<0 称X与Y负相关，协方差=0 称X与Y不相关

随机变量X和Y相互独立，则不相关；反之不行。

**相关系数**

为了避免X和Y的比例变换影响协方差，则对其进行标准化，对X和Y分别除以各自的标准差，得到相关系数：

$$ρ_{XY} = \frac{\mathrm{Cov}[X,Y]}{\sqrt{\mathrm{V}[X]}\sqrt{\mathrm{V}[Y]}}$$

相关系数取值为-1 ~ +1；相关系数越接近+1，则(X,Y)越趋向于左下右上方向的直线；相关系数越接近-1，则(X,Y)越趋向于左上右下方向的直线

协方差与相关系数都有局限性，不能完全代表数据情况

## 协方差矩阵
对于随机变量 $X_1,\cdots,X_n$，其中两两的方差或协方差可以构成一个矩阵，被称为协方差矩阵，或方差-协方差矩阵，该矩阵为对称矩阵：

$$\begin{pmatrix}
\mathrm{V}[X_1]&\mathrm{Cov}[X_1,X_2]&\cdots&\mathrm{Cov}[X_1,X_n]\\
\mathrm{Cov}[X_2,X_1]&\mathrm{V}[X_2]&\cdots&\mathrm{Cov}[X_2,X_n]\\
\vdots&\vdots&\ddots&\vdots\\
\mathrm{Cov}[X_n,X_1]&\mathrm{Cov}[X_n,X_2]&\cdots&\mathrm{V}[X_n]\\
\end{pmatrix}$$

**向量值随机变量与协方差矩阵**

将一系列的随机变量，列为一个列向量，称为向量值随机变量：
$$\boldsymbol{X}\equiv\begin{pmatrix} X_1\\X_2\\\vdots\\X_n \end{pmatrix}$$

则协方差矩阵可以表示为：（这里仍然用 $\mathrm{V}$ 符号，也有书用 $\Sigma$ 或 $\mathrm{Cov}$ 符号）
$$\mathrm{V}[\boldsymbol{X}]=\mathrm{E}[(\boldsymbol{X}-\boldsymbol{\mu})(\boldsymbol{X}-\boldsymbol{\mu})^T]\qquad其中\boldsymbol{\mu}\equiv\mathrm{E}[\boldsymbol{X}]$$

**向量值随机变量的运算**

设 $\boldsymbol{X}$ 为n元随机列向量，或者叫n元向量值随机变量
$$\mathrm{E}[\boldsymbol{X}]\equiv
\begin{pmatrix}
\mathrm{E}[X_1]\\ \mathrm{E}[X_2]\\ \vdots\\ \mathrm{E}[X_n]\\
\end{pmatrix}$$
$$\mathrm{E}[c\boldsymbol{X}] = c\mathrm{E}[\boldsymbol{X}] \quad（c为数值常量）$$
$$\mathrm{E}[\boldsymbol{X}+\boldsymbol{a}] = \mathrm{E}[\boldsymbol{X}]+\boldsymbol{a} \quad（\boldsymbol{a}为相同维度的固定向量）$$
$$\mathrm{E}[\boldsymbol{X}+\boldsymbol{Y}] = \mathrm{E}[\boldsymbol{X}]+\mathrm{E}[\boldsymbol{Y}]\quad (\boldsymbol{Y}为另外一个向量值随机变量)$$
$$\mathrm{E}[\boldsymbol{a}\cdot\boldsymbol{X}] = \mathrm{E}[\boldsymbol{a}^T\boldsymbol{X}] = \boldsymbol{a}^T\mathrm{E}[\boldsymbol{X}] = \boldsymbol{a}\cdot\mathrm{E}[\boldsymbol{X}]\quad（\boldsymbol{a}为相同维度的固定向量）$$
$$\mathrm{E}[A\boldsymbol{X}] = A\mathrm{E}[\boldsymbol{X}]\quad（A为维度匹配的固定值矩阵）$$

设矩阵 $R$ 由多个向量值随机变量组成：
$$R=\Bigg(\begin{array}{c|c|c}
\boldsymbol{R}_1&\cdots&\boldsymbol{R}_k
\end{array}\Bigg)$$
$$\mathrm{E}[AR]=A\mathrm{E}[R],\ \mathrm{E}[RB]=\mathrm{E}[R]B,\ \mathrm{E}[ARB]=A\mathrm{E}[R]B\quad（A、B为固定值矩阵）$$
$$\mathrm{E}[cR]=c\mathrm{E}[R],\ 
\mathrm{E}[R+A]=\mathrm{E}[R]+A,\ 
\mathrm{E}[R+S]=\mathrm{E}[R]+\mathrm{E}[S],\ 
\mathrm{E}[R^T]=\mathrm{E}[R]^T$$

引入向量值随机变量的概率与密度函数定义：
$$f_\boldsymbol{X}(\boldsymbol{x})\equiv f_{X_1,\cdots,X_n}(x_1,\cdots,x_n), 其中\boldsymbol{x}\equiv\begin{pmatrix} x_1\\\vdots\\x_n \end{pmatrix}$$

则有向量值随机变量的概率定义（书写方式为理工领域的省略方式，严格的需要重积分）：
$$\mathrm{P}(\boldsymbol{X}处于某一范围D内)=\int_Df_\boldsymbol{X}(\boldsymbol{x})\mathrm{d}\boldsymbol{x}$$

向量值随机变量的期望值也可简写为：（其中 $\boldsymbol{R}^n$ 表示n元实向量空间）
$$\mathrm{E}[\boldsymbol{X}]=\int_{\boldsymbol{R}^n}\boldsymbol{x}f_\boldsymbol{X}(\boldsymbol{x})\mathrm{d}\boldsymbol{x}$$
$$\mathrm{E}[g(\boldsymbol{X})]=\int_{\boldsymbol{R}^n}g(\boldsymbol{x})f_\boldsymbol{X}(\boldsymbol{x})\mathrm{d}\boldsymbol{x}$$

向量值随机变量的独立性：
$$\boldsymbol{X},\boldsymbol{Y},\boldsymbol{Z}独立 \Leftrightarrow\forall\boldsymbol{x,y,z}:\ f_{\boldsymbol{X,Y,Z}}(\boldsymbol{x,y,z})=f_{\boldsymbol{X}}(\boldsymbol{x})f_{\boldsymbol{Y}}(\boldsymbol{y})f_{\boldsymbol{Z}}(\boldsymbol{z})$$

还有很多实数值和离散值的公式，也可推广到向量值

**协方差矩阵的变量变换**
$$\mathrm{V}[a\boldsymbol{X}]=a^2\mathrm{V}[\boldsymbol{X}]\quad(a为数值常量)$$
$$\mathrm{V}[\boldsymbol{a}^T\boldsymbol{X}]=\boldsymbol{a}^T\mathrm{V}[\boldsymbol{X}]\boldsymbol{a}\quad(\boldsymbol{a}为固定值列向量)$$
$$\mathrm{V}[A^T\boldsymbol{X}]=A^T\mathrm{V}[\boldsymbol{X}]A\quad(A为固定值矩阵)$$
$$\mathrm{V}[\boldsymbol{X}+\boldsymbol{a}]=\mathrm{V}[\boldsymbol{X}]$$
$$\mathrm{V}[\boldsymbol{X+Y}]=\mathrm{V}[\boldsymbol{X}]+\mathrm{V}[\boldsymbol{Y}]$$

**任意方向的发散程度**

协方差矩阵 $\mathrm{V}[\boldsymbol{X}]$ 的对角线部分为方差 $\mathrm{V}[X_1],\mathrm{V}[X_2],\cdots,\mathrm{V}[X_n]$，他们分别表示自己方向上的发散程度

对于任意方向（用单位长度的向量 $\boldsymbol{u}$ 表示）， 则 $\boldsymbol{X}$ 向 $\boldsymbol{u}$ 投影得到 $Z$ （$Z$为实数值随机向量），即：
$$Z= \boldsymbol{u}^T\boldsymbol{X} = \|\boldsymbol{X}\|\cos\theta$$

则在 $\boldsymbol{u}$ 方向上的发散程度为：
$$\mathrm{V}[Z] = \mathrm{V}[\boldsymbol{u}^T\boldsymbol{X}] = \boldsymbol{u}^T\mathrm{V}[\boldsymbol{X}]\boldsymbol{u}$$

## 多元正态分布
**多元标准正态分布**

由n个遵从标准正态分布的i.i.d.随机变量组成的列向量 $\boldsymbol{Z}\equiv(Z_1,\cdots,Z_n)^T$

$\boldsymbol{Z}$ 的概率密度函数为：
$$f_\boldsymbol{Z}(\boldsymbol{z})=d\exp(-\frac{1}{2}\|\boldsymbol{z}\|^2)\qquad(d为使总概率为1的常量)$$

期望与协方差矩阵：
$$\mathrm{E}[\boldsymbol{Z}]=\boldsymbol{o}\qquad(\boldsymbol{o}表示零向量)$$
$$\mathrm{V}[\boldsymbol{Z}]=\begin{pmatrix}
1&0&\cdots&0\\0&1&\cdots&0\\\vdots&\vdots&\ddots&\vdots\\0&0&\cdots&1
\end{pmatrix}
=I\qquad(I表示单位矩阵)$$

综上，记作 $\boldsymbol{Z}\sim\mathrm{N}(\boldsymbol{o},I)$ ，即遵从n元标准正态分布

**多元一般正态分布**

对n元标准正态分布 $\mathrm{N}(\boldsymbol{o},I)$ 进行变换：

**缩放与位移**：设 $\boldsymbol{X}=\sigma\boldsymbol{Z}+\boldsymbol{\mu}$，则变换为
$$\mathrm{E}[\boldsymbol{X}]=\boldsymbol{\mu}，\mathrm{V}[\boldsymbol{X}]=\sigma^2 I$$

**纵向缩放与横向缩放**：设 $\boldsymbol{X}=(\sigma_1Z_1,\cdots,\sigma_n Z_n)^T+\boldsymbol{\mu}$，则变换为：
$$\mathrm{E}[\boldsymbol{X}]=\boldsymbol{\mu}，\mathrm{V}[\boldsymbol{X}] = D^2=\mathrm{diag}(\sigma_1^2,\cdots,\sigma_n^2)$$

可以记为 $\mathrm{N}(\boldsymbol{\mu}, D^2)$ 的多元正态分布

**旋转变换**：

设 $\boldsymbol{X}\equiv D\boldsymbol{Z}$，则 $\boldsymbol{X}\sim\mathrm{N}(\boldsymbol{o},D^2)$，再乘上一个正交矩阵 $Q$（正交矩阵为满足 $Q^TQ=I$），得到 $\boldsymbol{Y}\equiv Q\boldsymbol{X}$，则：
$$\mathrm{E}[\boldsymbol{Y}]=Q\mathrm{E}[\boldsymbol{X}]=\boldsymbol{o}$$
$$\mathrm{V}[\boldsymbol{Y}]=Q\mathrm{V}[\boldsymbol{X}]Q^T=QD^2Q^T$$

记 $V=QD^2Q^T$，给定 $V$ 的情况下，可以使用一种通过对称矩阵和正交矩阵实现矩阵对角化的方法来计算 $Q$ 和 $D$。

以上称之为遵从多元正态分布 $\mathrm{N}(\boldsymbol{o},V)$

另外也可以最后加上位移 $\boldsymbol{\mu}$ 而成为一般的多元正态分布 $\mathrm{N}(\boldsymbol{\mu}, V)$

**独立性**

符合正态分布的多个随机变量构成的向量值随机变量，并不一定遵从多元正态分布。

符合正态分布且独立的多个随机变量构成的向量值随机变量，必定遵从多元正态分布。

**多元正态分布的概率密度函数**

遵从n元标准正态分布 $\mathrm{N}(\boldsymbol{o},I)$ 的 $\boldsymbol{Z}$，其概率密度函数为：
$$f_\boldsymbol{Z}(\boldsymbol{z}) = \frac{1}{\sqrt{2\pi}^n}\exp(-\frac{1}{2}\|\boldsymbol{z}\|^2)$$

可以推导出多元一般正态分布 $\boldsymbol{X}\sim\mathrm{N}(\boldsymbol{\mu}, V)$ 的概率密度函数为：
$$f_\boldsymbol{X}(\boldsymbol{x}) = \frac{1}{\sqrt{(2\pi)^n\mathrm{det}V}}\exp(-\frac{1}{2}(\boldsymbol{x}-\boldsymbol{\mu})^TV^{-1}(\boldsymbol{x}-\boldsymbol{\mu}))$$

可以抽象为：$f(\boldsymbol{x})=\Box\exp(\boldsymbol{x}的元素的二次式)$（$\Box$为不含 $\boldsymbol{x}$ 的常量）

反之，如果 $\boldsymbol{X}$ 的概率密度函数符合上式，则其分布就是一种正态分布

## 多元正态分布性质
* 可以由期望值向量与协方差矩阵确定具体分布
* 如果各随机变量不相关，则一定独立（非正态分布则不一定）
* 多元正态分布在做线性边缘后仍然是多元正态分布

## 截面（条件分布）
**“多元正态分布的条件分布也是多元正态分布”**

假设 $\boldsymbol{X}\equiv(X_1,X_2,\cdots,X_n)^T$遵从n元正态分布在给定条件 $X_1=c$ 条件下，条件分布的概率密度函数为：

$$f_{\boldsymbol{\tilde{X}}|X_1}(x_2,\cdots,x_n|c)$$

可以推导出符合 $\Box\exp(\boldsymbol{\tilde{x}}的二次式)$，因此遵从n-1元正态分布

从图像角度来看，n=3时，概率密度函数的等值面是椭球体，而椭球体的截面也是椭圆

PS：截面可能偏离椭球主轴，所以截面的中心点不一定在原分布的主轴上

一般化为：
$$\begin{pmatrix} \boldsymbol{X}\\\boldsymbol{Y}\end{pmatrix}\sim
\mathrm{N}\Big(
  \begin{pmatrix} \boldsymbol{\mu}\\\boldsymbol{v} \end{pmatrix},
  \begin{pmatrix} 甲&乙\\乙^T&丁 \end{pmatrix}
\Big)$$
则给定 $\boldsymbol{X}=\boldsymbol{c}$，$\boldsymbol{Y}$ 的条件分布为 $\mathrm{N}(\boldsymbol{\tilde{v}},\boldsymbol{\tilde{W}})$：
$$\boldsymbol{\tilde{v}}\equiv\boldsymbol{v}+乙^T甲^{-1}(\boldsymbol{c}-\boldsymbol\mu)$$
$$\boldsymbol{\tilde{W}}\equiv丁-乙^T甲^{-1}乙$$

## 投影（边缘分布）
**“多元正态分布的边缘分布也是多元正态分布”**

从图像角度来看，n=3时，椭球体的投影也是一个椭圆

边缘分布的期望值向量和协方差矩阵，就是从原期望值向量和协方差矩阵中去除掉投影的项目位置所对应的行与列。例如一个3元正态分布向第1维度投影：（$\boldsymbol{X}\equiv(X_1,X_2,X_3)^T$，$\boldsymbol{\tilde{X}}\equiv(X_2,X_3)^T$）

$$\mathrm{E}[\boldsymbol{X}]=
\begin{pmatrix} \mathrm{E}[X_1]\\ \hline \mathrm{E}[X_2]\\ \mathrm{E}[X_3] \end{pmatrix}
=\begin{pmatrix} *\\ \hline \\ \mathrm{E}[\boldsymbol{\tilde{X}}]\\ \end{pmatrix}$$

$$
\mathrm{V}[\boldsymbol{X}]=
\Bigg(\begin{array}{c|cc}
\mathrm{V}[X_1]&\mathrm{Cov}[X_1,X_2]&\mathrm{Cov}[X_1,X_3]\\
\hline
\mathrm{Cov}[X_2,X_1]&\mathrm{V}[X_2]&\mathrm{Cov}[X_2,X_3]\\
\mathrm{Cov}[X_3,X_1]&\mathrm{Cov}[X_3,X_2]&\mathrm{V}[X_3]\\
\end{array}\Bigg)=
\Bigg(\begin{array}{c|cc}
*&*&*\\
\hline
*&&\\
*&&\mathrm{V}[\boldsymbol{\tilde{X}}]\\
\end{array}\Bigg)
$$

## 卡方分布
$\boldsymbol{Z}\sim \mathrm{N}(\boldsymbol{o},I)$ 的长度 $\|\boldsymbol{Z}\|$ 的概率密度函数并非随长度增加而下降，而是根据元数 $n$ 的不同而决定 

设 $n$ 元标准正态分布的长度的平方的分布为自由度为 $n$ 的 $\chi^2$ 分布（卡方分布）

$\chi^2$ 分布的概率密度函数为：（其中 $\Gamma$ 代表 $\Gamma$函数）
$$f(x)=\begin{cases}
\frac{1}{2\Gamma(n/2)}(\frac{n}{2})^{n/2-1}\exp(-\frac{x}{2})&(x\ge 0)\\
0&(x<0)\\
\end{cases}$$

当 $n=2$ 时，$\chi^2$ 分布概率密度函数为 $f(x)=(1/2)\exp(-x/2)$，这与普通指数函数形式相似，在后文中可以用来生成遵从正态分布的伪随机数

## 协方差矩阵与椭圆的关系
一般分布的图像不一定是椭圆（或者椭球、超椭球体，下同），但仍然可以获得其基准椭圆

对向量值随机变量 $\boldsymbol{X}$，求 $\boldsymbol{\mu}≡\mathrm{E}[\boldsymbol{X}]$ 和 $V≡\mathrm{V}[\boldsymbol{X}]$，然后根据多元正态分布 $\mathrm{N}(\boldsymbol{\mu}, V)$ 绘制对应的基准椭圆

**（实例一）单位矩阵与圆**

如果协方差矩阵 $V$ 是单位矩阵 $I$，根据先前计算，在任意方向 $\boldsymbol{u}$ 上的方差均为1（也就是标准差为1）

因此可以构建一个以 $\mathrm{E}[\boldsymbol{X}]$ 为中心，半径为1的圆（n=2时是圆，n=3时是球体，n>3时是超球体）

PS：这个圆无法覆盖大部分可取的值，因为只是圆半径只是标准差

PPS： $\boldsymbol{X}$ 的概率密度函数的等高线并不一定就是圆

**（实例二）对角矩阵与椭圆**

如果协方差矩阵 $V$ 是对角阵：$\mathrm{V}[\boldsymbol{X}]=\mathrm{diag}(v_1, v_2,\cdots,v_n)$

可以通过各方向变换，让 $V$ 变为单位矩阵，绘制基准圆，然后再反变换的方式，变成基准椭圆

其各个方向的半径为 $\sqrt{v_1},\sqrt{v_2},\cdots,\sqrt{v_n}$

任意方向发散程度与标准差的匹配仍然符合，即任意方向上的标准差，等于这个椭圆在这个方向上的投影尺寸半径

**（实例三）一般矩阵与倾斜的椭圆**

将一般矩阵进行空间变换为对角阵，绘制基准椭圆，再变换回去

可以推导出存在正交矩阵 $Q$，使得 $Q^TV[\boldsymbol{X}]Q$ 为对角阵 $\mathrm{diag}(\lambda_1,\lambda_2,\cdots,\lambda_n)$，则可以取 $A=Q^T$ 作为变换矩阵

矩阵 $Q$ 中的每个特征向量 $\boldsymbol{q}_i$ 都与椭圆的主轴同向，且椭圆各主轴半径为$\sqrt{\lambda_i}$

$$\Huge{协方差矩阵就是椭圆}$$

协方差矩阵局限性：当观察3个以上随机变量时，协方差矩阵只是看到两两之间的关系，但无法发掘高阶相关

# 第6章 估计与检验
## 估计的概念
例如抛硬币，正面向上概率为 $p$，而且i.i.d.，抛 $n$ 次，会得到 $n$ 个随机变量 $X_1,X_2,\cdots,X_n$ 的观测值，此时正面向上的比例，称之为“经验分布”

上帝视角：平行世界整体 $\Omega$ 中的每个世界 $\omega$ 都会形成自己对 $X_1,X_2,\cdots,X_n$ 的观测结果，整体 $\Omega$ 内统计每个随机变量都是符合正面 $p$ 与反面 $1-p$ 比例的，但每个世界 $\omega$ 内只能观察到自己的部分

* 假定真实观测值与真实分布相关，切试图根据观测值来推测真实分布
* 由于观测值取值随机，因此由他们计算得到的估计值也是随机值
* 估计方式多种多样，且不同估计方式得到的估计值也有所不同

非参数估计
* 没有给出分布的具体函数形式的问题
 
参数估计（以下的讨论内容）
* 期望值与方差不确定性但遵从正态分布的问题

## 估计方法
假设 $X_1,X_2,\cdots,X_n$ 都遵从某一正态分布 $\mathrm{N}(\mu,\sigma^2)$，基于观测值来推算 $\mu$ 就属于一种参数估计，而推算 $\sigma^2$ 也是一种参数估计

通常情况下，条件给出的数据分布可以由有限维度的向量值参数 $\theta≡(\theta_1,\cdots,\theta_k)$ 确定，需要做的就是通过观测值估计 $θ$ 的值（此处只讨论点估计）

此后记 $X=(X_1,X_2,\cdots,X_n)$，$\theta$ 的估计值（或叫估计方法）记为 $\hat\theta$，或明确写为 $\hat\theta(X)$ 来表示与 $X$ 相关


**如何评价一种估计方法 $\hat\theta$ ？**

选择最佳估计量的评价基准多种多样，常用的比如平方误差的期望：
$$R_{\hat\theta}(\theta) = \mathrm{E}[\|\hat\theta(X)-\theta\|^2]\qquad（其中X是随机值，\theta 为固定值）$$

对于不同的正确答案 $θ$，平方误差期望值 $R_{\hat\theta}(\theta)$ 也不同

一般来说无法找到一个在所有 $\theta$ 上均优于其他方法的评估方法，所以需要进行“多目标优化”

设 $\check{x}_i$ 为 $X_i$ 的观测值，记 $\check{x}$ 为 $X$ 的观测值

**（策略一) 减少候选项——最小方差无偏估计（UMVUE）**

无偏性是一种常见的筛选条件
$$\forall\theta:\qquad \mathrm{E}[\hat\theta(X)] = \theta$$

对于遵从正态分布的i.i.d.数据，使用观测值的平均值 $\bar{X}\equiv(X_1+\cdots+X_n)/n$ 来估计期望值 $\mu$ 就是 UMVUE

而 $S^2≡\frac{1}{n-1}\sum_{i=1}^{n}(X_i-\bar{X})^2$ 则是对方差 $\sigma^2$ 的UMVUE（一般来说，分母为 $(n-1)$ 可以称为无偏方差，而分母为 $n$ 的称为样本方差；但也有人将分母为 $(n-1)$ 的称之为样本方差）

**（策略二）弱化最优定义——最大似然估计**

不要求全能的最优解，只要求：
* 一致性：样本容量 $n\to\infty$ 时，估计结果收敛于正确结果
* 渐进有效性：样本容量 $n\to\infty$ 时，$n\mathrm{E}[(估计结果-正确答案)^2]$ 收敛于理论边界

符合如上条件的最常见的估计方法就是最大似然估计

最大似然估计（离散值），求使以下概率最大化的 $\theta$：（随后对数化便于计算）
$$\mathrm{P}(X_1=\check{x}_1,\cdots,X_n=\check{x}_n)$$
$$\log\mathrm{P}(X_1=\check{x}_1,\cdots,X_n=\check{x}_n)=\log\mathrm{P}(X_1=\check{x}_1)+\cdots+\log\mathrm{P}(X_n=\check{x}_n)$$

最大似然估计（随机值），求使以下概率最大化的 $\theta$：（随后对数化便于计算）
$$f_{X_1,\cdots,X_n}(\check{x}_1,\cdots,\check{x}_n)$$
$$\log f_{X_1,\cdots,X_n}(\check{x}_1,\cdots,\check{x}_n)=\log f_{X_1}(\check{x}_1)+\cdots+\log f_{X_n}(\check{x}_n)$$

最大似然估计相比UMVUE来说：
* 可以通过简单计算求得
* 对参数进行变换后估计结果依然符合要求，例如 $\sigma^2$ 的最大似然估计为 $\widehat{\sigma^2}$，那么 $\sigma$ 的最大似然估计则为 $\sqrt{\widehat{\sigma^2}}$
* 一致性与渐进有效性可以通过适当假设条件得到，当样本容量极大时，两者几乎等价

采用最大似然估计对上述问题进行求解，根据真实分布参数 $\theta$ 下观测到观测值 $\check{x}$ 的概率最大化

可以求得 $\mu$ 的最大似然估计为 $\bar{\check{x}}$（观测值 $\check{x}_i$ 的平均值）

求得 $\sigma^2$ 的最大似然估计为 $\frac{1}{n}\sum_{i=1}^{n}(\check{x}_i - \bar{\check{x}})^2$ （对比前面的无偏方差估计分母 $n-1$）

**（策略三）以单一数值作为评价基准——贝叶斯估计**

假定参数 $θ$ 也是一个随机变量，称之为先验分布，将 $X$ 视为给定 $θ$ 下的条件分布

由推导可得，当 $\hat\theta=\mathrm{E}[\theta|X=\check{x}]$] 时，平均误差的条件期望 $\mathrm{E}[(\hat\theta-\theta)^2|X=\check{x}]$ 最小。但也可以不给出条件 $X=\check{x}$ 时的确定值 $\hat\theta$，而是给出 $X=\check{x}$ 时 $\theta$ 的条件分布，称之为后验分布

如果后验分布范围较广，则准确率较低；反之，准确率较高，可信度更高。

例子：扔硬币，正面向上概率为 $R$，已知 $R$ 的先验分布概率函数 $f_R(r)$，求连续扔 $n$ 次均为正面向上的后验分布和条件期望。
* 后验分布 $f_{R|S}(r|n) = \frac{\mathrm{P}(S=n|R=r)f_R(r)}{\int_0^1 \mathrm{P}(S=n|R=u)f_R(u)\mathrm{d}u}$
* 条件期望 $\mathrm{E}[R|S=n] = \int_0^1 rf_{R|S}(r|n) \mathrm{d}r$

**贝叶斯派与概率派的争议**
* 贝叶斯估计更加考虑了先验分布，能够避免没见过的情况导致绝对化的错误
* 但反对者认为先验分布直接影响答案准确性，先验分布过于随意
* 当样本容量n增加时，先验分布的作用逐渐变小，逐渐趋近于最大似然（毕竟越来越多的事实，也让人不得不相信）

## 检验理论
> 甲：我俩比赛了100次，我赢了61次，所以我比你更强  
> 乙：不，这纯属偶然  
> 甲：如果只是偶然，那出现现在这种情况的概率小于5%，这几乎不可能

* 虚无假设 $H_0$：甲获胜概率=0.5 ……甲试图驳斥的主张
* 对立假设 $H_1$：甲获胜概率>0.5 ……甲试图肯定的主张

甲方试图证明的论点：如果 $H_0$ 成立，得到 $H_1$ 这样的数据概率仅有 $\triangle\triangle$，因此 $H_0$ 很可能是错误的

其中 $\triangle\triangle$ 称为 $p$ 值（$p$-value），设置显著性水平阈值 $\alpha$（一般取0.05或0.01）
* 如果 p值<α 则拒绝对照假设 $H_0$，接受支持 $H_1$ 的主张
* 如果 p值>=α 则无法拒绝/接受对照假设 $H_0$，无法判断谁更正确

>例子：  
>假设100次比赛为随机变量 $X_1,\cdots,X_{100}$（i.i.d.），每个 $X_i$ 当甲赢则为1，否则为0。  
>如果按照虚无假设（双方势均力敌），则根据 $S\sim\mathrm{Bn}(100,1/2)$，而 $\mathrm{P}(S\ge 61)\approx 0.02$，这小于显著性水平0.05，则对立假设被接受，甲确实实力更强

检验理论，与估计理论一样，都是有一堆可以根据输入数据而输出检验结果的程序/方法，需要从中寻找最优方法。为了比较优劣，引入：
* 第一类错误（false reject）：本应为 $H_0$ 却错误地拒绝了它。又称Ⅰ型错误或弃真错误，发生概率记为 $α$
* 第二类错误（false accept）：$H_0$ 不是正确答案却错误地接受了它。又称Ⅱ型错误或存伪错误，发生概率记为 $β$

**检验原理的第一原理**：

寻找最优检验程序 $δ$，因为需要优先优化第一种错误，所以排除掉第一种错误发生概率高于 $\alpha$ 的程序，然后选择第二种错误发生概率 $\beta$ 较低的程序即可。

**简单假设**

将 $n$ 个实数值随机值合记为 $X=(X_1,X_2,\cdots,X_n)$，如果有一种假设能直接给出 $X$ 的分布，则称之为简单假设。例如：

* 虚无假设 $H_0$：$X$ 的概率密度函数为 $g_0(x)$ ……希望驳斥的主张
* 对立假设 $H_1$：$X$ 的概率密度函数为 $g_1(x)$ ……希望肯定的主张

寻找检验程序 $δ$，记 $δ$ 收到输入数据 $X$ 时的输出结果为 $δ(X)$，从而描述排除标准：
$$对于 H_0，\mathrm{P}(δ(X)=“拒绝”) \le \alpha$$

换而言之，对于 $x=(x_1,x_2,\cdots,x_n)$ ，以下不等式成立：
$$\int_A g_0(x)\mathrm{d}u \le \alpha \qquad（积分范围A是由所有满足δ(X)=“拒绝”的x组成的集合）$$

我们希望在所有符合条件的 $δ$ 中找到第二类错误发生概率 $β$ 最小的程序，其中 $β$ 定义为：
$$对于 H_1，\mathrm{P}(δ(X)=“接受”)$$

换而言之，积分计算为：
$$\int_B g_1(x)\mathrm{d}u \qquad（积分范围B是所有 δ(X)=“接受” 的 x 组成的集合）$$

形象化比喻：青虫吃菜叶问题，菜叶里有营养和微量毒素，毒素的分布为 $g_0(x)$ ㎎/㎠，营养的分布为 $g_1(x)$ ㎎/㎠，青虫最多可以承受 $α$ ㎎ 的毒素，希望获得最多营养，那么吃哪一块？

一般而言，设毒素浓度 $g_0(x)$ 和营养浓度 $g_1(x)$ 随位置 $x$ 连续变化，先求 $g_1(x)/g_0(x)$ 并按结果从大到小排序，当毒素累积达到 $α$ 时停滞，此时 $g_1(x)/g_0(x)=c$，因此应当选择吃 $g_1(x)/g_0(x)>c$ 的所有部分

即最佳检验程序的判断标准为：
$$\delta(x)=\begin{cases}
“拒绝”&(g_1(x)/g_0(x)>c)\\
“接受”&(g_1(x)/g_0(x)\le c)\\
\end{cases}$$

通过调节 $c$ ，使得第一类错误发生概率恰为 $α$ —— 这就是**奈曼·皮尔逊引理**

**复合假设**

复合假设包括了多个分布，需要面临多目标优化相似的问题。具体方法包括一致最大功效无偏检验（UMPUT）、最大似然比检验等 （不再展开）

----
* {% post_link probability-and-statistics-note-1 %}
* {% post_link probability-and-statistics-note-2 %}
* {% post_link probability-and-statistics-note-3 %}