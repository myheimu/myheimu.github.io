---
title: 《程序员的数学3：线性代数》笔记4
date: 2019-05-20
updated: 2019-05-20
categories:
- 数学
tags:
- 读书笔记
- 线性代数
permalink: linear-algebra-note-4
mathjax: true
---

* {% post_link linear-algebra-note-1 %}
* {% post_link linear-algebra-note-2 %}
* {% post_link linear-algebra-note-3 %}
* {% post_link linear-algebra-note-4 %}

----

# 第5章 计算机上的计算（2）——特征值算法
高次代数方程在计算机中求解，受到精度影响误差可能很大

那么可以绕开解特征方程方法，通过寻找可逆矩阵 $P$，使得 $P^{-1}AP=(对角矩阵或上三角矩阵)$ （即对角化或上三角化），从而使得对角元素就是要求的特征值

## 伽罗华（Galois）理论
**n次代数方程**，例如1到4次的代数方程：
$$\begin{aligned}
ax+b&=0\\
ax^2+bx+c&=0\\
ax^3+bx^2+cx+d&=0\\
ax^4+bx^3+cx^2+dx+e&=0\\
\end{aligned}$$

1次方程解为 $x=-\frac{b}{a}$，2次方程解为 $x=\frac{-b\pm\sqrt{b^2-4ac}}{2a}$，3次方程使用Cardano公式（Tartaglia公式），4次方程使用Ferrari公式

**“5次及以上代数方程没有求解公式”** （求解公式限于对系数进行加减乘除、方根等基础运算）

对于任意方阵A'，可以进行相似变换到 A：
$$A=\begin{pmatrix}
0&0&\cdots&0&-a_0\\
1&0&\cdots&0&-a_1\\
0&1&\ddots&\vdots&\vdots\\
\vdots&\ddots&\ddots&0&-a_{n-2}\\
0&\cdots&0&1&-a_{n-1}\\
\end{pmatrix}$$

则特征方程可以通过计算 $\det(\lambda I-A)$ 得到，即：
$$\lambda^n+a_{n-1}\lambda^{n-1}+a_{n-2}\lambda^{n-2}+\cdots+a_1\lambda+a_0=0$$

称矩阵 A 为此代数方程的**友矩阵**

由于伽罗华理论，所以也可以推断出**“5次以上矩阵的特征值一定不存在通用的求解方法/求解步骤”**

只有一些通过不断逼近，求近似值的方法，比如 Jacobi 方法和 QR 方法

## Jacobi方法
Jacobi 方法是 Carl Gustav Jacob Jacobi 于1846年发表的算法，即使放在现在而言，对于10×10以内矩阵，它也是很有效的算法，即便对于更大的矩阵，虽然速度比QR等算法慢一些，但精度上更佳

另外 Jacobi 方法也可以用于（近似）对角化

### 平面旋转
定义 $n\times n$ 矩阵：
$$R(\theta,p,q)=\begin{pmatrix}
1\\
&\ddots\\
&&1\\
&&&\cos\theta&&&&-\sin\theta\\
&&&&1\\
&&&&&\ddots\\
&&&&&&1\\
&&&\sin\theta&&&&\cos\theta\\
&&&&&&&&1\\
&&&&&&&&&\ddots\\
&&&&&&&&&&1\\
\end{pmatrix}\quad(空白元素都是0)\\
\cos\theta位于(p,p)和(q,q)位置\\
\sin\theta位于(q,p)位置，-\sin\theta位于(p,q)位置$$

也就是说 $R(\theta,p,q)$ 几乎就是一个n阶单位矩阵，只是其中四个位置被替换成了2*2旋转矩阵中的四个元素：
$$R(\theta)=\begin{pmatrix}\cos\theta&-\sin\theta\\\sin\theta&\cos\theta\end{pmatrix}$$

考虑 $R(\theta,1,2)$，其几何含义就是将三维空间内的点，保持 z 轴不变，在 x-y 平行平面上旋转 $\theta$ 角度；考虑 $R(\theta,2,3)$，其几何含义就是保持 x 轴不变，在 y-z 平行平面上旋转；考虑 $R(\theta,1,3)$，即保持 y 轴不变，在 x-z 平行平面上旋转

一般而言：
$$R(\theta,p,q)\begin{pmatrix}x_1\\\vdots\\x_p\\\vdots\\x_q\\\vdots\\x_n\end{pmatrix}=
\begin{pmatrix}x_1\\\vdots\\x_p\cos\theta-x_q\sin\theta\\\vdots\\x_p\sin\theta+x_q\cos\theta\\\vdots\\x_n\end{pmatrix}$$

几何含义为，除了 $x_p$ 和 $x_q$ 以外，其他轴位置不变，而在第 p 和第 q 轴构成平面上，受到旋转矩阵 $R(\theta)$ 的影响

旋转矩阵 $R(\theta)$ 满足 $R(\theta)R(\theta)^T=I$，即为正交矩阵，有转置矩阵等于逆矩阵

同样也可推导出 $R(\theta,p,q)$ 是正交矩阵，有转置矩阵等于逆矩阵

### 通过平面旋转进行相似变换
Jacobi 方法就是：对于给定矩阵 A，选择不同的 $p,q,\theta$，通过平面旋转反复进行如下相似变换，直到矩阵接近对角化形式为止：
$$A'=R(\theta,p,q)^TAR(\theta,p,q)$$

可以推导如下：（详细推导略）
$$\begin{pmatrix}
&&a'_{1p}&&a'_{1q}\\
&&\vdots&&\vdots\\
a'_{p1}&\cdots&a'_{pp}&\cdots&a'_{pq}&\cdots&a'_{pn}\\
&&\vdots&&\vdots\\
a'_{q1}&\cdots&a'_{qp}&\cdots&a'_{qq}&\cdots&a'_{qn}\\
&&\vdots&&\vdots\\
&&a'_{np}&&a'_{nq}\\
\end{pmatrix}\\
=R(\theta,p,q)^T
\begin{pmatrix}
&&a_{1p}&&a_{1q}\\
&&\vdots&&\vdots\\
a_{p1}&\cdots&a_{pp}&\cdots&a_{pq}&\cdots&a_{pn}\\
&&\vdots&&\vdots\\
a_{q1}&\cdots&a_{qp}&\cdots&a_{qq}&\cdots&a_{qn}\\
&&\vdots&&\vdots\\
&&a_{np}&&a_{nq}\\
\end{pmatrix}
R(\theta,p,q)\\（空白位置的元素数值不变）$$

由于 Jacobi 处理的矩阵 A是对称矩阵，所以变化的数值公式为：
$$a'_{pj}=\phantom{-}a_{pj}\cos\theta+a_{qj}\sin\theta\quad (j\ne p,q)\\
a'_{qj}=-a_{pj}\sin\theta+a_{qj}\cos\theta\quad (j\ne p,q)\\
a'_{ip}=\phantom{-}a_{ip}\cos\theta+a_{iq}\sin\theta\quad (i\ne p,q)\\
a'_{iq}=-a_{ip}\sin\theta+a_{iq}\cos\theta\quad (i\ne p,q)\\
a'_{pp}=a_{pp}\cos^2\theta+a_{qq}\sin^2\theta+2a_{pq}\sin\theta\cos\theta\\
a'_{qq}=a_{pp}\sin^2\theta+a_{qq}\cos^2\theta-2a_{pq}\sin\theta\cos\theta\\
a'_{pq}=a_{pq}(\cos^2\theta-\sin^2\theta)+(a_{qq}-a_{pp})\sin\theta\cos\theta$$

为了尽量对角化，则期望相似变换后使得 $a'_{pq}=0$，可以推导出：
$$\frac12\tan(2\theta)=\frac{a_{pq}}{a_{pp}-a_{qq}}\\
\theta=\frac12\tan^{-1}\frac{2a_{pq}}{a_{pp}-a_{qq}}$$

另外为了观察矩阵是否朝着对角化方向靠近，定义函数：
$$f(A)=\sum_{i\ne j}a_{ij}^2,\quad g(A)=\sum_i a_{ii}^2$$

期待非对角元素平方和 $f(A)$ 能够越来越小，然而可以计算得到 $a_{pj},a_{qj}$ 变化之后，$f(A)$ 并没有变化，因此只有 $a_{pq},a_{qp}$ 的变化才会影响 $f(A)$：
$$f(A')=f(A)-2a_{pq}^2$$

因此整体逻辑就是寻找使 $a_{pq}$ 最大的 $p,q\ (p\ne q)$，并反复进行使得 $a'_{pq}=0$ 的旋转，使得 $f(A)$ 趋向于0

### 计算过程优化
并不需要真的计算出 $\theta$，前面已经得知 $\tan(2\theta)$ 的值，则：
$$\cos\theta=\sqrt{\frac12(1+\frac{1}{\sqrt{1+\tan^2 2\theta}})}\\
\sin\theta=\sqrt{1-\cos^2\theta}$$

## 幂法原理
幂法可以用于求绝对值最大、最小的特征值，乃至所有特征值，但主要为后面QR方法和反幂法做铺垫

### 求绝对值最大的特征值
在矩阵 $A(\ne O)$ 可对角化情况下，按特征值绝对值大小排序：
$$\begin{cases}
A\boldsymbol{x}_1=\lambda_1\boldsymbol{x}_1\\
A\boldsymbol{x}_2=\lambda_2\boldsymbol{x}_2\\\vdots\\
A\boldsymbol{x}_n=\lambda_n\boldsymbol{x}_n\\
\end{cases}\qquad
|\lambda_1|\ge|\lambda_2|\ge\cdots\ge|\lambda_n|
$$

适当选择初始向量 $\boldsymbol{v}$，反复左乘矩阵 $A$，则会渐渐靠近 $A$ 的绝对值最大的特征值对应的特征向量方向：
$$\boldsymbol{v},A\boldsymbol{v},A^2\boldsymbol{v},A^3\boldsymbol{v},\cdots\rightarrow(\boldsymbol{x}_1的方向)$$

对于适当选择的初始向量：
$$\boldsymbol{v}=v_1\boldsymbol{x}_1+v_2\boldsymbol{x}_2+\cdots+v_n\boldsymbol{x}_n$$

反复左乘 A，共 k 次，趋向无穷后，则有向量方向平行关系：
$$A^k\boldsymbol{v} \mathbin{\!/\mkern-5mu/\!} v_1\boldsymbol{x}_1+v_2(\frac{\lambda_2}{\lambda_1})^k\boldsymbol{x}_2+\cdots+v_n(\frac{\lambda_n}{\lambda_1})^k\boldsymbol{x}_n$$

只需要采用较大的 k，然后反推在该方向上伸缩了多少倍，除以 k，即得到绝对值最大的特征值 $\lambda_1$

在实际计算中为了避免数值过大过小导致精度问题，每一步需要进行归一化调整幅度

### 求绝对值最小的特征值
适当选择初始向量 $\boldsymbol{v}$，反复左乘逆矩阵 $A^{-1}$，则会渐渐靠近 $A$ 的绝对值最小的特征值对应的特征向量方向：
$$\boldsymbol{v},A^{-1}\boldsymbol{v},(A^{-1})^2\boldsymbol{v},(A^{-1})^3\boldsymbol{v},\cdots\rightarrow(\boldsymbol{x}_n的方向)$$

由于计算逆矩阵计算量较大，可以进行LU分解，然后将左乘 $A^{-1}$改变为计算线性方程组 $L\boldsymbol{z}=\boldsymbol{y}$ 和 $U\boldsymbol{x}=\boldsymbol{z}$

### QR分解
分解 $A=QR$，就是“Q是A的列向量的 **Gram-Schemidt 标准正交化**，R是在A的列向量的标准正交基下的坐标表示”

把矩阵 $A$ 分区为n个线性无关的n维列向量 $\boldsymbol{a}_1,\boldsymbol{a}_2,\cdots,\boldsymbol{a}_n$ 通过 Gram-Schemidt 方法进行正交化，得到正交基 $\boldsymbol{q}_1,\boldsymbol{q}_2,\cdots,\boldsymbol{q}_n$：
$$\begin{aligned}
\boldsymbol{q}_1=\boldsymbol{p}_1/\|\boldsymbol{p}_1\|, \quad& \boldsymbol{p}_1=\boldsymbol{a}_1\\
\boldsymbol{q}_2=\boldsymbol{p}_2/\|\boldsymbol{p}_2\|, \quad& \boldsymbol{p}_2=\boldsymbol{a}_2-(\boldsymbol{a}_2\cdot\boldsymbol{q}_1)\boldsymbol{q}_1\\
\boldsymbol{q}_3=\boldsymbol{p}_3/\|\boldsymbol{p}_3\|, \quad&\boldsymbol{p}_3=\boldsymbol{a}_3-(\boldsymbol{a}_3\cdot\boldsymbol{q}_1)\boldsymbol{q}_1-(\boldsymbol{a}_3\cdot\boldsymbol{q}_2)\boldsymbol{q}_2\\
\vdots\\
\boldsymbol{q}_n=\boldsymbol{p}_n/\|\boldsymbol{p}_n\|, \quad&
\boldsymbol{p}_n=\boldsymbol{a}_n-(\boldsymbol{a}_n\cdot\boldsymbol{q}_1)\boldsymbol{q}_1-\cdots-(\boldsymbol{a}_{n}\cdot\boldsymbol{q}_{n-1})\boldsymbol{q}_{n-1}\\
\end{aligned}$$

采用以上列向量 $\boldsymbol{q}_i$ 同样方式构成矩阵 $Q$

定义：
$$r_{ii}=\|\boldsymbol{p}_i\| \quad (1\le i \le n)\\
r_{ij}=\boldsymbol{a}_j\cdot\boldsymbol{q}_i\quad (1\le i < j \le n)$$

则可以将 Gram-Schemidt 标准正交化公式，改写为：
$$\begin{pmatrix}
a_{11}&a_{12}&\cdots&a_{1n}\\
a_{21}&a_{22}&\cdots&a_{2n}\\
\vdots&\vdots&\ddots&\vdots\\
a_{n1}&a_{n2}&\cdots&a_{nn}\\
\end{pmatrix}=
\begin{pmatrix}
q_{11}&q_{12}&\cdots&q_{1n}\\
q_{21}&q_{22}&\cdots&q_{2n}\\
\vdots&\vdots&\ddots&\vdots\\
q_{n1}&q_{n2}&\cdots&q_{nn}\\
\end{pmatrix}
\begin{pmatrix}
r_{11}&r_{12}&\cdots&r_{1n}\\
0&r_{22}&\cdots&r_{2n}\\
\vdots&\ddots&\ddots&\vdots\\
0&\cdots&0&r_{nn}\\
\end{pmatrix}$$

这就是矩阵 A 的 QR分解，把最右边矩阵记作 $R$，则为：
$$A=QR$$

因为矩阵 Q 各列都经过标准正交化，所以 $Q^TQ=I$，Q为正交矩阵，因此任意一个列向量线性无关的矩阵 A，都可以分解为正交矩阵 Q 和上三角矩阵 R 的乘积形式

实际之中并不会采用 Gram-Schemidt 标准正交化方法，因为会累计误差，而是多采用基于平面旋转变换和镜像变换算法

#### 正交矩阵集合构成李群
对于“n×n矩阵的全体”所构成集合中某个子集满足以下几点，则构成“群”：

- 该子集中含有单位矩阵
- 该子集中的矩阵的逆矩阵也在该子集内
- 该子集中的任意两个矩阵的乘积也在该子集内

可以得知“n×n正交矩阵的全体”所构成集合，“可逆的n×n上三角矩阵的全体”所构成的集合都符合上述“群”定义，并且他们是“连续的”矩阵群，也就是所谓“李群”的一种

### 求所有特征值
选择 n 个适当的线性无关的初始向量 $\boldsymbol{v}_1,\boldsymbol{v}_2,\cdots,\boldsymbol{v}_n$，对其反复左乘 A，然后把所有结果进行 Gram-Schemidt 标准正交化，那么最终结果就会接近 A 的特征向量所张成的子空间的标准正交基

对于按绝对值大小排列、且不存在绝对值相等的特征值 $\lambda_1,\lambda_2,\cdots,\lambda_n$，对应的特征向量 $\boldsymbol{x}_1,\boldsymbol{x}_2,\cdots,\boldsymbol{x}_n$

设 $A^k\boldsymbol{v}_1,A^k\boldsymbol{v}_2,\cdots,A^k\boldsymbol{v}_n$ 标准正交化之后得到 $\boldsymbol{q}_1(k),\boldsymbol{q}_2(k),\cdots,\boldsymbol{q}_n(k)$

随着 k 增大后，会有：（证明略，主要思想就是 r 个向量$\boldsymbol{v}_i$进行反复左乘 A，张成的 r 维空间，会突出前 r 个绝对值最大的特征值的方向）
$$\begin{aligned}
&\mathrm{span}\{\boldsymbol{q}_1(k)\}\rightarrow \mathrm{span}\{\boldsymbol{x}_1\}\\
&\mathrm{span}\{\boldsymbol{q}_1(k),\boldsymbol{q}_2(k)\}\rightarrow \mathrm{span}\{\boldsymbol{x}_1,\boldsymbol{x}_2\}\\
&\quad\vdots\\
&\mathrm{span}\{\boldsymbol{q}_1(k),\boldsymbol{q}_2(k),\cdots,\boldsymbol{q}_n(k)\}\rightarrow \mathrm{span}\{\boldsymbol{x}_1,\boldsymbol{x}_2,\cdots,\boldsymbol{x}_n\}\\
\end{aligned}$$

以上 $\boldsymbol{q}_i$ 作为列向量拼成的矩阵 $Q(k)$，即为 QR 分解结果：
$$A^kV=Q(k)R(k)$$

（证明略）可以推导 $Q(k)^TAQ(k)$ 会趋近于上三角矩阵，则计算该上三角矩阵，其对角元素就是特征值

## QR方法
QR 方法是 Francis 于1961年发表的算法，对于对称矩阵和非对称矩阵均使用

### QR方法原理
#### QR 迭代基本流程

- 对需要求解特征值的矩阵进行 QR 分解：$A_{k-1}=Q_{k-1}R_{k-1}$
- 对分解出来的结果进行逆向相乘：$A_k=R_{k-1}Q_{k-1}$

反复执行以上流程，最终将趋近一个上三角矩阵，其对角元素就是原矩阵的特征值

对于存在绝对值相等的特征值，幂法不能使用，所以本方法也不能简单套用；实矩阵存在复特征值情况，也不适用

#### 相似性
对于一步计算：
$$A_{k+1}=R_kQ_k=Q_k^{-1}Q_kR_kQ_k=Q_k^{-1}A_kQ_k$$

因此每一步，都是基于正交矩阵 $Q_k$ 进行相似变换，因此特征值不变

#### 趋向上三角矩阵
对于从 $A_0$ 出发，进行相似变换到第 k 次时：
$$A_k=Q_{k-1}^{-1}\cdots Q_{0}^{-1}A_0Q_0\cdots Q_{k-1}$$

可以整理为：
$$A_k=(Q_0Q_1\cdots Q_{k-1})^{-1}A_0(Q_0Q_1\cdots Q_{k-1})$$

考虑对 $A_0^k$ 进行 QR分解，例如 $k=3$ 时：
$$\begin{aligned}
A_0^3&=(Q_0R_0)(Q_0R_0)(Q_0R_0)\\
&=Q_0(R_0Q_0)(R_0Q_0)R_0\\
&=Q_0(Q_1R_1)(Q_1R_1)R_0\\
&=Q_0Q_1(A_2)R_1R_0\\
&=(Q_0Q_1Q_2)(R_2R_1R_0)
\end{aligned}$$

正交矩阵乘积依然是正交矩阵，上三角矩阵乘积仍然是上三角矩阵，所以可以得到：
$$Q_0Q_1\cdots Q_{k-1}\ 正是\ A_0^k\ 的\ QR\ 分解正交矩阵$$

又由于 $A_0^kI=Q(k)R(k)\Rightarrow Q(k)=Q_0Q_1\cdots Q_{k-1}$

则 QR 方法中的第 k 步出现的 $A_k$，实际上与以单位矩阵为初始矩阵的幂法的第 k 步得到的矩阵一致，因此也是趋向上三角矩阵

### Hessenberg矩阵
实际使用 QR 方法时，会先进行相似变化，得到 Hessenberg 矩阵的形式，如下：
$$\begin{pmatrix}
*&*&*&*&*\\
*&*&*&*&*\\
0&*&*&*&*\\
0&0&*&*&*\\
0&0&0&*&*\\
\end{pmatrix}$$

即在上三角矩阵基础上，对角线左下方一条斜线也不为零

可以推导，Hessenberg 矩阵在进行 QR迭代之后，仍然能保持 Hessenberg 形式，从而减少计算量（证明略）

### Householder方法
Householder 方法可以将一般的非对称矩阵通过相似变换约化为 Hessenberg 矩阵

**镜像变换**指把空间中任意一点，变换到经过原点的某一超平面对称的另一点

令“经过原点的超平面”的单位法向量为 $\boldsymbol{u}$，那么 $\boldsymbol{u}\boldsymbol{u}^T$ 为把任意向量正投影到单位法向量所在直线上的线性变换

则镜像变换公式为：
$$\boldsymbol{x}'=(I-2\boldsymbol{u}\boldsymbol{u}^T)\boldsymbol{x}$$

镜像变换的矩阵为： $H=I-2\boldsymbol{u}\boldsymbol{u}^T$，（证明略）它为对称矩阵、正交阵

**例子**：尝试把一个 4×4 矩阵变换为 Hessenberg 矩阵

给定两个向量 $\boldsymbol{x},\boldsymbol{y}$，它们模长一致，考虑以 $\boldsymbol{x}-\boldsymbol{y}$ 为法向量的超平面，则其镜像变换为：
$$H=I-2\boldsymbol{u}\boldsymbol{u}^T,\quad \boldsymbol{u}=\frac{\boldsymbol{x}-\boldsymbol{y}}{\|\boldsymbol{x}-\boldsymbol{y}\|}$$

$$H\boldsymbol{x}=\boldsymbol{y},\quad H\boldsymbol{y}=\boldsymbol{x}$$

对于其中的 $\boldsymbol{x}$ 无限制，但特别设置 $\boldsymbol{y}$ 除了第1分量之外均为0，可以设为：
$$\boldsymbol{y}=(|\boldsymbol{x}|,0,0)^T$$

则该映射 H 为从 $\boldsymbol{x}=(x,y,z)^T$ 到 $\boldsymbol{y}=(\|\boldsymbol{x}\|,0,0)^T$

$$\left(\begin{array}{c|ccc}
1&0&0&0\\\hline 0\\0&&H\\0\\
\end{array}\right)
\begin{pmatrix}*&*&*&*\\x&*&*&*\\y&*&*&*\\z&*&*&*\end{pmatrix}=
\begin{pmatrix}*&*&*&*\\\|\boldsymbol{x}\|&*&*&*\\0&*&*&*\\0&*&*&*\end{pmatrix}$$

根据对应位置的 x,y,z 生成对应的镜像变换矩阵 H，随后执行如上变换，随后再右乘相同矩阵

$$\begin{pmatrix}*&*&*&*\\\|\boldsymbol{x}\|&*&*&*\\0&*&*&*\\0&*&*&*\end{pmatrix}
\left(\begin{array}{c|ccc}
1&0&0&0\\\hline 0\\0&&H\\0\\
\end{array}\right)=
\begin{pmatrix}*&*&*&*\\\|\boldsymbol{x}\|&*&*&*\\0&*&*&*\\0&*&*&*\end{pmatrix}$$

则通过这次相似变换，完成了第一列的 Hessenberg 化

后续迭代，直到变成 Hessenberg 矩阵

### Hessenberg矩阵的QR迭代
仍然以 4×4 矩阵为例，执行左乘旋转矩阵变换，做到相应位置 $a'_{pq}=0$：
$$A_k=\begin{pmatrix}*&*&*&*\\*&*&*&*\\0&*&*&*\\0&0&*&*\end{pmatrix} \Rightarrow R(\theta_1,1,2)^TA_k=\begin{pmatrix}*&*&*&*\\\boxed{0}&*&*&*\\0&*&*&*\\0&0&*&*\end{pmatrix}$$

$$R(\theta_2,2,3)^TR(\theta_1,1,2)^TA_k=\begin{pmatrix}*&*&*&*\\0&*&*&*\\0&\boxed{0}&*&*\\0&0&*&*\end{pmatrix}$$

$$R(\theta_3,3,4)^TR(\theta_2,2,3)^TR(\theta_1,1,2)^TA_k=\begin{pmatrix}*&*&*&*\\0&*&*&*\\0&0&*&*\\0&0&\boxed{0}&*\end{pmatrix}=R$$

则完成 QR 分解：
$$R=R(\theta_3,3,4)^TR(\theta_2,2,3)^TR(\theta_1,1,2)^TA_k\\
Q=R(\theta_1,1,2)R(\theta_2,2,3)R(\theta_3,3,4)$$

### 原点位移、降阶
实际中，通常会先想办法得到一个特征值的估计值 $\hat{\lambda}$，然后用 $A-\hat\lambda I$ 来代替 $A$ 进行 QR 迭代，称之为**原点位移**

在迭代过程中，第 n 行的非对角元素将加速趋近于 0（公式中的 $\boxed{0}$），从而尽早获得一个特征值 $\blacksquare$：
$$\begin{pmatrix}
*&*&*&*\\
*&*&*&*\\
0&*&*&*\\
0&0&\boxed{0}&\blacksquare
\end{pmatrix}$$

从而可以将第 n 列和第 n 行去除，获得一个 n-1 维方阵，继续计算，迭代下去

### 对称矩阵的情况
对一般的对称矩阵使用 Householder 变换，可以得到对称的 Hessenberg 矩阵，也就是**三对角矩阵**：
$$\begin{pmatrix}
*&*&0&\cdots&0\\
*&*&*&\ddots&\vdots\\
0&*&*&\ddots&0\\
\vdots&\ddots&\ddots&\ddots&*\\
0&\cdots&0&*&*\\
\end{pmatrix}$$

后续 QR 迭代，将不断趋近于对角矩阵

### 反幂法（反迭代法）
对于矩阵 A 的某一个特征值 $\lambda_k$，假设现在得到一个精度一般的近似值 $\hat\lambda_k$

则矩阵 $A-\hat\lambda_k I$ 会有一个很小的特征值 $\lambda_k-\hat\lambda_k$，则采用幂法求绝对值最小的特征值的算法，从而得到修正值，从而提高精度
